{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0f1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from super_learner import*\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm, t\n",
    "from scipy.special import logit, expit\n",
    "import random\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62120861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(N, outcome_type, treatment_type):\n",
    "\n",
    "    W1 = np.random.binomial(1, 0.5, N)\n",
    "    W2 = np.random.binomial(1, 0.65, N)\n",
    "    W3 = np.round(np.random.uniform(0, 4, N), decimals=3)\n",
    "    W4 = np.round(np.random.uniform(0, 5, N), decimals=3)\n",
    "\n",
    "    if treatment_type == 'binary':\n",
    "        Ap = expit(-0.4 + 0.2*W2 + 0.15*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "        A = np.random.binomial(1, Ap, N)\n",
    "        \n",
    "    elif treatment_type == 'multigroup':\n",
    "        Ap1 = expit(-0.4 + 0.2*W2 + 0.3*W3 + 0.1*W4 + 0.4*W2*W4)\n",
    "        Ap2 = expit(-0.4 + 0.5*W2 + 0.1*W3 + 0.2*W4 + 0.1*W2*W4)\n",
    "        Ap3 = expit(-0.4 + 0.7*W2 + 0.5*W3 + 0.3*W4 + 0.2*W2*W4)\n",
    "        Ap4 = expit(-0.4 + 0.1*W2 + 0.2*W3 + 0.4*W4 + 0.1*W2*W4)\n",
    "        Ap = np.array([Ap1, Ap2, Ap3, Ap4]).T\n",
    "        Ap = (Ap / Ap.sum(1).reshape(-1,1))\n",
    "        \n",
    "        l = [0,1,2,3]\n",
    "        A = []\n",
    "        for i in range(len(Ap)):\n",
    "            ap = Ap[i]\n",
    "            onehot = np.zeros((4,1))\n",
    "            choice = random.choices(l, ap)\n",
    "            onehot[choice] = 1\n",
    "            A.append(onehot)\n",
    "        A = np.concatenate(A,1).T\n",
    "\n",
    "\n",
    "    if outcome_type == 'cls':\n",
    "        \n",
    "        if treatment_type  == 'binary':\n",
    "            Y1p = expit(-1 + 1 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            Y0p = expit(-1 + 0 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            Y1 = np.random.binomial(1, Y1p, N)\n",
    "            Y0 = np.random.binomial(1, Y0p, N)\n",
    "            Y = Y1*A + Y0*(1-A)\n",
    "            \n",
    "        if treatment_type == 'multigroup':         \n",
    "            Y3p = expit(-1 + 1 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            Y2p = expit(-1 + 2 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            Y1p = expit(-1 + 0.5 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            Y0p = expit(-1 + 4 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4)\n",
    "            \n",
    "            Y3 = np.random.binomial(1, Y3p, N)\n",
    "            Y2 = np.random.binomial(1, Y2p, N)\n",
    "            Y1 = np.random.binomial(1, Y1p, N)\n",
    "            Y0 = np.random.binomial(1, Y0p, N)\n",
    "\n",
    "            Y = A[:, 3] * Y3 + A[:, 2] * Y2 +  A[:, 1] * Y1 +  A[:, 0] * Y0\n",
    "            \n",
    "        \n",
    "    elif outcome_type == 'reg':\n",
    "        \n",
    "        if treatment_type == 2:\n",
    "            Y1 = -1 + 2*A -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4\n",
    "            Y0 = -1 + 0 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4\n",
    "\n",
    "            Y = Y1*A + Y0*(1-A)\n",
    "        \n",
    "        if treatment_type == 'multigroup':       \n",
    "            Y3 = -1 + 1 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4\n",
    "            Y2 = -1 + 2 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4\n",
    "            Y1 = -1 + 0.5 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4\n",
    "            Y0 = -1 + 3 -0.1*W1 + 0.3*W2 + 0.25*W3 + 0.2*W4 + 0.15*W2*W4   \n",
    "\n",
    "            Y = A[:, 3] * Y3 + A[:, 2] * Y2 +  A[:, 1] * Y1 +  A[:, 0] * Y0\n",
    "        Y = np.clip(Y, -1, 6)\n",
    "            \n",
    "    if treatment_type == 'multigroup':\n",
    "        data = pd.DataFrame([W1, W2, W3, W4, A, Y, Y0, Y1, Y2, Y3]).T\n",
    "        data.columns = ['W1', 'W2', 'W3', 'W4', 'Adummy', 'Y', 'Y0','Y1', 'Y2', 'Y3']\n",
    "        \n",
    "        A_group = []\n",
    "        for a in data.Adummy.values:\n",
    "            val = np.where(a==1)\n",
    "            A_group.append(val[0])\n",
    "        A_group = np.concatenate(A_group)\n",
    "        data['A'] = A_group \n",
    "    elif treatment_type == 'binary':\n",
    "        data = pd.DataFrame([W1, W2, W3, W4, A, Y, Y1, Y0]).T\n",
    "        data.columns = ['W1', 'W2', 'W3', 'W4', 'A', 'Y', 'Y1','Y0']\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71bb7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.5 -0.9999999999999996 -1.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "outcome_type = 'reg'   # cls or reg\n",
    "treatment_type = 'multigroup' # binary or multigroup\n",
    "N = 100\n",
    "data = generate_data(N=N, outcome_type=outcome_type, treatment_type=treatment_type)\n",
    "\n",
    "true_psi_1_0 = data.Y1.mean() - data.Y0.mean()\n",
    "true_psi_2_0 = data.Y2.mean() - data.Y0.mean()\n",
    "true_psi_3_0 = data.Y3.mean() - data.Y0.mean()\n",
    "print(true_psi_1_0, true_psi_2_0, true_psi_3_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2a733904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLP(object):\n",
    "    def __init__(self, data, cause, outcome, confs, precs, QSLdict, GSLdict, outcome_type='reg',\n",
    "                 outcome_upper_bound=None, outcome_lower_bound=None, multigroup=False):\n",
    "        \n",
    "        # general settings\n",
    "        self.multigroup = multigroup\n",
    "        self.outcome_type = outcome_type   # reg or cls\n",
    "        self.outcome_upper_bound = outcome_upper_bound  # for bounded outcomes\n",
    "        self.outcome_lower_bound = outcome_lower_bound  # for bounded outcomes\n",
    "        \n",
    "        # data and variable names\n",
    "        self.data = data  # pd.DataFrame()\n",
    "        self.n = len(self.data)\n",
    "        self.cause = cause\n",
    "        self.outcome = outcome\n",
    "        self.confs = confs\n",
    "        self.precs = precs\n",
    "\n",
    "        self.Q_X = self.data[list(set(confs)) + list(set(precs)) + [cause]]\n",
    "        self.G_X = self.data[list(set(confs))]\n",
    "        self.Q_Y = self.data[outcome].astype('int') if outcome_type == 'cls' else self.data[outcome]\n",
    "        \n",
    "        self.A = self.data[cause]\n",
    "        self.A_dummys = self.A.copy()\n",
    "        self.A_dummys =  self.A_dummys.astype('category')\n",
    "        self.A_dummys = pd.get_dummies(self.A_dummys, drop_first=False)\n",
    "        \n",
    "        if (self.outcome_upper_bound is not None) and (self.outcome_type == 'reg'):\n",
    "            self.Q_Y = (self.Q_Y - self.outcome_lower_bound)/(self.outcome_upper_bound - self.outcome_lower_bound)\n",
    "        \n",
    "        self.G_Y = self.data[cause]\n",
    "        self.groups = np.unique(self.A)\n",
    "        \n",
    "        \n",
    "        # Super Learners:\n",
    "        self.QSLdict = QSLdict\n",
    "        self.GSLdict = GSLdict\n",
    "        self.gslr = None\n",
    "        self.qslr = None\n",
    "        \n",
    "        # targeting and prediction storage\n",
    "        self.Gpreds = None\n",
    "        self.QAW = None\n",
    "        self.Qpred_groups = {}\n",
    "        self.Gpreds = None\n",
    "        self.first_estimates = {}\n",
    "        self.first_effects = {}\n",
    "        self.updated_estimates = {}\n",
    "        self.updated_effects = {}\n",
    "        self.clev_covs = {}\n",
    "        self.epsilons = {}\n",
    "        self.ses = {}\n",
    "        self.ps = {}\n",
    "        \n",
    "\n",
    "            \n",
    "    def fit(self, k, standardized_outcome=False):\n",
    "        \n",
    "        print('Training G Learners...')\n",
    "        self.gslr = SuperLearner(output='proba', est_dict=self.GSLdict, k=k, standardized_outcome=False)\n",
    "        self.gslr.fit(x=self.G_X, y=self.G_Y)\n",
    "        # PROPENSITY SCORES\n",
    "        print('Generating G Predictions ')\n",
    "        self.Gpreds = self.gslr.predict_proba(self.G_X)\n",
    "        \n",
    "        print('Training Q Learners...')\n",
    "        self.qslr = SuperLearner(output=outcome_type, est_dict=self.QSLdict, k=k, standardized_outcome=False)\n",
    "        self.qslr.fit(x=self.Q_X, y=self.Q_Y)\n",
    "        \n",
    "        # QAW SCORES\n",
    "        print('Generating QAW Predictions ')\n",
    "        self.QAW = self.qslr.predict(self.Q_X) if self.outcome_type == 'reg' else self.qslr.predict_proba(self.Q_X)[:,1:]\n",
    "        if self.outcome_upper_bound is not None and self.outcome_type == 'reg':\n",
    "            print('Bounding outcome predictions.')\n",
    "            self.QAW = np.clip(self.QAW, 0, 1)\n",
    "        \n",
    "        print('SuperLearner Training Completed.')\n",
    "        \n",
    "        \n",
    "    def target_multigroup(self, group_comparisons=None):\n",
    "        \n",
    "        # INTERVENTIONAL Y PREDS\n",
    "        print('Generating Predictions for Counterfactual Outcomes')\n",
    "        for group in self.groups:\n",
    "            int_data = self.Q_X.copy()\n",
    "            int_data[self.cause] = group\n",
    "            self.Qpred_groups[group] = self.qslr.predict(int_data)\n",
    "            \n",
    "        # GROUP DIFFERENCES\n",
    "        for group_comparison in group_comparisons:\n",
    "            group_a = group_comparison[0]\n",
    "            group_ref = group_comparison[1]\n",
    "\n",
    "            group_a_preds = self.Qpred_groups[group_a]\n",
    "            group_ref_preds = self.Qpred_groups[group_ref]\n",
    "            \n",
    "            difference = (group_a_preds - group_ref_preds)\n",
    "            self.first_estimates[str(group_comparison)] = difference\n",
    "            \n",
    "        # CLEVER COVARIATES\n",
    "        print('Estimating Clever Covariates')\n",
    "        for group_comparison in group_comparisons:\n",
    "            group_a = group_comparison[0]\n",
    "            group_ref = group_comparison[1]\n",
    "            group_a_inv_prop = 1 / self.Gpreds[:, group_a]\n",
    "            group_not_a_inv_prop = - 1 / (1 - self.Gpreds[:, group_a])\n",
    "            group_clev_cov = ((self.A_dummys.iloc[:, group_a] / self.Gpreds[:, group_a]) - (1 - self.A_dummys.iloc[:, group_a]) / (1 - self.Gpreds[:, group_a])).values \n",
    "            self.clev_covs[str(group_comparison)] = (group_clev_cov, group_a_inv_prop, group_not_a_inv_prop)\n",
    "            \n",
    "       # ESTIMATE FLUCTUATION PARAMETERS     \n",
    "        print('Estimating Fluctuation Parameters')\n",
    "        for group_comparison in group_comparisons:\n",
    "            group_a = group_comparison[0]\n",
    "            group_ref = group_comparison[1]\n",
    "            group_clev_cov = self.clev_covs[str(group_comparison)][0]\n",
    "            if self.outcome_type == 'cls' or self.outcome_upper_bound is not None:\n",
    "                eps = sm.GLM(np.asarray(self.Q_Y).astype('float'), group_clev_cov, offset=logit(self.QAW[:,0]), family=sm.families.Binomial()).fit().params[0]\n",
    "            else:\n",
    "                eps = (sm.GLM(np.asarray(self.Q_Y).astype('float'), group_clev_cov, offset=self.QAW[:,0]).fit()).params[0]\n",
    "            self.epsilons[str(group_comparison)] = eps\n",
    "            \n",
    "        # UPDATING PREDICTIONS\n",
    "        print('Updating Initial Counterfactual Predictions')\n",
    "        for group_comparison in group_comparisons:\n",
    "            group_a = group_comparison[0]\n",
    "            group_ref = group_comparison[1]\n",
    "            group_a_orig = self.Qpred_groups[group_a]\n",
    "            group_ref_orig = self.Qpred_groups[group_ref]\n",
    "            \n",
    "            self.first_effects[str(group_comparison)] = group_a_orig.mean() - group_ref_orig.mean()\n",
    "            eps = self.epsilons[str(group_comparison)]\n",
    "            clev_cov_a = self.clev_covs[str(group_comparison)][1]\n",
    "            clev_cov_ref = self.clev_covs[str(group_comparison)][2]\n",
    "            \n",
    "            if self.outcome_type == 'cls' or self.outcome_upper_bound is not None:\n",
    "                group_a_update = (expit(logit(group_a_orig) + eps * clev_cov_a))\n",
    "                group_ref_update = (expit(logit(group_ref_orig) + eps * clev_cov_ref))\n",
    "            else:\n",
    "                group_a_update = (group_a_orig + eps * clev_cov_a)\n",
    "                group_ref_update = (group_ref_orig + eps * clev_cov_ref)\n",
    "            \n",
    "            self.updated_estimates[str(group_comparison)] = (group_a_update, group_ref_update)\n",
    "            self.updated_effects[str(group_comparison)] = group_a_update.mean() - group_ref_update.mean()\n",
    "           \n",
    "        \n",
    "        print('Deriving the Influence Function')\n",
    "        for group_comparison in group_comparisons:\n",
    "            group_a = group_comparison[0]\n",
    "            group_ref = group_comparison[1]\n",
    "            clev_cov_group = self.clev_covs[str(group_comparison)][0]\n",
    "            ystar_a, ystar_ref = self.updated_estimates[str(group_comparison)][0], self.updated_estimates[str(group_comparison)][1]\n",
    "            effect_star = self.updated_effects[str(group_comparison)]\n",
    "            IC =  clev_cov_group.reshape(-1, 1)*(self.Q_Y.values - self.QAW) + (ystar_a - ystar_ref) - effect_star\n",
    "            IC_var = np.var(IC,ddof=1)\n",
    "            print(IC.shape)\n",
    "            se = (IC_var / self.n)**0.5\n",
    "            p = 2*(1 - t.cdf(np.abs(effect_star)/se, 2*self.n))\n",
    "            self.ses[str(group_comparison)] = se\n",
    "            self.ps[str(group_comparison)] = p\n",
    "            \n",
    "        \n",
    "        return self.first_effects, self.updated_effects, self.ses, self.ps\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c0e95c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_dict_reg = {'Elastic': ElasticNet(), 'SVR': SVR(),\n",
    "            'LR': LinearRegression(), 'RF': RandomForestRegressor(),\n",
    "            'MLP':MLPRegressor(alpha=0.001, max_iter=2000), 'AB': AdaBoostRegressor(), 'poly': 'poly'}\n",
    "\n",
    "est_dict_cls = {'LR':LogisticRegression(max_iter=500), 'MLP':MLPClassifier(alpha=0.001, max_iter=2000), \n",
    "            'SVC':SVC(probability=True), 'poly': 'poly', 'RF':RandomForestClassifier(),\n",
    "            'AB': AdaBoostClassifier()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c6c931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k =5\n",
    "tlp = TLP(data, cause='A', outcome='Y', confs=['W1', 'W2', 'W3', 'W4'],\n",
    "          precs=[], outcome_type=outcome_type, QSLdict=est_dict_reg, GSLdict=est_dict_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f173eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training G Learners...\n",
      "Training estimator: LR\n",
      "Training estimator: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewvowels/GitHub/PhD_part_1/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/matthewvowels/GitHub/PhD_part_1/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/matthewvowels/GitHub/PhD_part_1/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training estimator: SVC\n",
      "Training estimator: poly\n",
      "Training estimator: RF\n",
      "Training estimator: AB\n",
      "Training estimator on full data: LR\n",
      "Training estimator on full data: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthewvowels/GitHub/PhD_part_1/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training estimator on full data: SVC\n",
      "Training estimator on full data: poly\n",
      "Training estimator on full data: RF\n",
      "Training estimator on full data: AB\n",
      "Generating G Predictions \n",
      "Training Q Learners...\n",
      "Training estimator: Elastic\n",
      "Training estimator: SVR\n",
      "Training estimator: LR\n",
      "Training estimator: RF\n",
      "Training estimator: MLP\n",
      "Training estimator: AB\n",
      "Training estimator: poly\n",
      "Training estimator on full data: Elastic\n",
      "Training estimator on full data: SVR\n",
      "Training estimator on full data: LR\n",
      "Training estimator on full data: RF\n",
      "Training estimator on full data: MLP\n",
      "Training estimator on full data: AB\n",
      "Training estimator on full data: poly\n",
      "Generating QAW Predictions \n",
      "SuperLearner Training Completed.\n",
      "Generating Predictions for Counterfactual Outcomes\n",
      "Estimating Clever Covariates\n",
      "Estimating Fluctuation Parameters\n",
      "Updating Initial Counterfactual Predictions\n",
      "Deriving the Influence Function\n",
      "(100, 100)\n",
      "(100, 100)\n",
      "(100, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'[1, 0]': -1.9686690653793022,\n",
       "  '[2, 0]': -1.121283946196094,\n",
       "  '[3, 0]': -1.7860461693414502},\n",
       " {'[1, 0]': -2.4291314615965236,\n",
       "  '[2, 0]': -0.8244598520799435,\n",
       "  '[3, 0]': -1.8962390437418595},\n",
       " {'[1, 0]': 0.1920663376521216,\n",
       "  '[2, 0]': 0.20448978953648506,\n",
       "  '[3, 0]': 0.2013644216341761},\n",
       " {'[1, 0]': 0.0, '[2, 0]': 7.86813391004948e-05, '[3, 0]': 0.0})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlp.fit(k=k, standardized_outcome=False)\n",
    "group_comparisons =[[1,0],[2,0],[3,0]]  # comparison in list format with 'group A [vs] reference_group'\n",
    "tlp.target_multigroup(group_comparisons=group_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0395fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.5 -0.9999999999999996 -1.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "print(true_psi_1_0, true_psi_2_0, true_psi_3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c2d1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "clev_cov_group = tlp.clev_covs['[1, 0]'][0]\n",
    "ystar_a, ystar_ref = tlp.updated_estimates['[1, 0]'][0], tlp.updated_estimates['[1, 0]'][1]\n",
    "effect_star = tlp.updated_effects['[1, 0]']\n",
    "IC =  clev_cov_group.reshape(-1, 1)*(tlp.Q_Y.values - tlp.QAW) + (ystar_a - ystar_ref) - effect_star\n",
    "print(IC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b68af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a153b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834322f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f3cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2685912c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2f8c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
